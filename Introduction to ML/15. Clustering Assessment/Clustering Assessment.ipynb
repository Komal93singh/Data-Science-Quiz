{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13bd9f24",
   "metadata": {},
   "source": [
    "# Quiz: Clustering Assessment\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ae333",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c18bfd1",
   "metadata": {},
   "source": [
    "### Q1.  What does the Davies-Bouldin index measure in clustering evaluation? \n",
    "1. The optimal number of clusters \n",
    "2. The ratio of within-cluster scatter to between cluster separation \n",
    "3. The density of clusters \n",
    "4. The similarity between predicted and true labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ae6df",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. The ratio of within-cluster scatter to between-cluster separation**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "The **Davies-Bouldin index (DBI)** is a metric used to evaluate the quality of clustering. It measures the average similarity between each cluster and its most similar one, where similarity is defined as the ratio of within-cluster scatter (how compact the cluster is) to between-cluster separation (how far apart the clusters are). Lower values of the Davies-Bouldin index indicate better clustering, meaning clusters are compact and well separated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39034cdc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c88b4cc",
   "metadata": {},
   "source": [
    "### Q2. What is the primary purpose of using intrinsic measures in clustering evaluation? \n",
    "1. To compare clustering results with ground truth labels \n",
    "2. To assess cluster quality without external reference labels \n",
    "3. To determine the optimal number of clusters \n",
    "4. To measure the computational efficiency of clustering algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb99401",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. To assess cluster quality without external reference labels**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Intrinsic measures evaluate clustering quality based only on the data and the clustering itself, without needing any external or ground truth labels. They analyze properties like cluster cohesion (how close points in a cluster are) and separation (how distinct clusters are), making them useful when true labels are unknown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc90021",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9715dd3",
   "metadata": {},
   "source": [
    "### Q3. In the context clustering, What does \"the curse of dimensionality\" refer to? \n",
    "1. The difficult in visualizing high-dimensional data \n",
    "2. The tendency of distance measures to become less meaningful in high-dimensional spaces \n",
    "3. The increased computational complexity of clustering algorithms in high dimensions \n",
    "4. All of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a126d5c3",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**4. All of the above**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "\"The curse of dimensionality\" in clustering and data analysis refers to multiple challenges that arise as the number of dimensions (features) increases:\n",
    "\n",
    "* **Difficulty in visualizing high-dimensional data** (option 1),\n",
    "* **Distance measures becoming less meaningful** because points tend to become equidistant in high dimensions (option 2),\n",
    "* **Increased computational complexity** for clustering algorithms as dimensions grow (option 3).\n",
    "\n",
    "All these factors together make clustering and other analysis tasks harder in high-dimensional spaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca7f74",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67812b70",
   "metadata": {},
   "source": [
    "### Q4. Which of the following is NOT a common linkage criterion in hierarchical clustering? \n",
    "1. Single linkage \n",
    "2. Complete linkage \n",
    "3. Average linkage \n",
    "4. Optimal linakge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1bde4",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**4. Optimal linakge**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "In hierarchical clustering, common linkage criteria include:\n",
    "\n",
    "* **Single linkage** (minimum distance between points in clusters),\n",
    "* **Complete linkage** (maximum distance between points in clusters),\n",
    "* **Average linkage** (average distance between points in clusters).\n",
    "\n",
    "**\"Optimal linkage\"** is not a standard or commonly used linkage method in hierarchical clustering. Also, note the spelling \"linakge\" is a typo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306e2ff0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bf77eef",
   "metadata": {},
   "source": [
    "### Q5. Which of the following statements about th eElbow Method is FALSE? \n",
    "1. It's used to determine the optimal number of clusters \n",
    "2. It plots the within-cluster sum of squares against the number of clusters \n",
    "3. The \"elbow\" point indicates the optimal number of clusters \n",
    "4. It always provides a clear and unambiguous result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9529a53",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**4. It always provides a clear and unambiguous result**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "The Elbow Method is a heuristic to help choose the optimal number of clusters by plotting the within-cluster sum of squares (WCSS) against the number of clusters and looking for a point (\"elbow\") where the rate of decrease sharply changes. However, this \"elbow\" is not always clear or unambiguous, making the method sometimes subjective and less reliable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2223f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84473441",
   "metadata": {},
   "source": [
    "### Q6. What is the primary advantage of hierarchical clustering over K-means? \n",
    "1. It's faster for large datasets \n",
    "2. It doesn't require specifying the number of clusters in advance \n",
    "3. It always produces globally optimal results \n",
    "4. It can only handle numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d165a6f",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. It doesn't require specifying the number of clusters in advance**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Hierarchical clustering builds a tree (dendrogram) showing cluster relationships at all levels, so you can choose the number of clusters afterward by cutting the tree at the desired level. In contrast, K-means requires you to specify the number of clusters **before** running the algorithm.\n",
    "\n",
    "Other points:\n",
    "\n",
    "* Hierarchical clustering is usually **slower** than K-means for large datasets.\n",
    "* It does **not** guarantee globally optimal results.\n",
    "* It can handle different types of data depending on the linkage and distance metrics, but it's often used with numerical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf1ead",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61455e16",
   "metadata": {},
   "source": [
    "### Q7. Which of the following is NOT a parameter in the DBSCAN algorithm? \n",
    "1. eps \n",
    "2. min_samples \n",
    "3. num_clusters \n",
    "4. metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3311f6bb",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. num_clusters**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) requires these parameters:\n",
    "\n",
    "* **eps**: The radius within which to search for neighboring points.\n",
    "* **min_samples**: The minimum number of points required to form a dense region (core point).\n",
    "* **metric**: The distance metric used to calculate distances between points (e.g., Euclidean).\n",
    "\n",
    "**num_clusters** is **not** a parameter in DBSCAN because the number of clusters is determined automatically based on the density and data distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b99d91",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc1f39fe",
   "metadata": {},
   "source": [
    "### Q8. In a contingency matrix for clustering evaluation, what do the off-diagonal elements represent? \n",
    "1. Correctly clustered data points \n",
    "2. Misclassified data points \n",
    "3. Noise points \n",
    "4. Cluster Centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa9a003",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Misclassified data points**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "In a contingency matrix (or confusion matrix) for clustering evaluation, the **diagonal elements** represent the number of correctly clustered data points (where predicted cluster matches the true class), while the **off-diagonal elements** represent data points that were assigned to the wrong clusterâ€”i.e., **misclassified** points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b01bcb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9204b622",
   "metadata": {},
   "source": [
    "### Q9. Which of the following is true about the V-Measure in clustering evaluation? \n",
    "1. It's the arithmetic mean of homogeneity and completeness \n",
    "2. It's the geometric mean of homogeneity and completeness \n",
    "3. It's the harmonic mean of homogeneity and completeness \n",
    "4. It's the maximum of homogeneity an dcompleteness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f962b650",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. It's the harmonic mean of homogeneity and completeness**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "The **V-Measure** is an external clustering evaluation metric defined as the harmonic mean of **homogeneity** (each cluster contains only members of a single class) and **completeness** (all members of a given class are assigned to the same cluster). Using the harmonic mean balances the two measures, rewarding clustering solutions that are good on both aspects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290cada",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f685901c",
   "metadata": {},
   "source": [
    "### Q10. What does the Homogeneity score measure in clustering evaluation? \n",
    "1. How well each cluster contains only members of a single class \n",
    "2. How well all members of a given class are assigned to the same cluster \n",
    "3. The balance between cluster sizes \n",
    "4. The optimal number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b18c48",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. How well each cluster contains only members of a single class**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "The **Homogeneity score** measures whether each cluster contains only data points which are members of a single class. In other words, it assesses how \"pure\" or homogeneous the clusters are with respect to the true class labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89876e1f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b364812",
   "metadata": {},
   "source": [
    "### Q11. What is the main advantage of using Batch K-means over standard K-means? \n",
    "1. It produces more accurate results \n",
    "2. It can handle non-linear data \n",
    "3. It's more computationally efficient for large datasets \n",
    "4. It automatically determines the optimal number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811258d3",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. It's more computationally efficient for large datasets**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**Batch K-means** processes data in small batches (mini-batches) rather than using the entire dataset at once, which makes it much faster and more scalable for large datasets compared to standard K-means. It sacrifices some accuracy for speed but is very useful when dealing with big data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f415d44d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e985bd9b",
   "metadata": {},
   "source": [
    "### Q12. Which of the following is NOT a characteristic of a good clustering result? \n",
    "1. High intra-cluster similarity \n",
    "2. Low Intra-cluster similarity \n",
    "3. High Inter-cluster similarity \n",
    "4. Well-separated clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b98eaf",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. High Inter-cluster similarity**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "A good clustering result should have:\n",
    "\n",
    "* **High intra-cluster similarity** (data points within the same cluster are similar),\n",
    "* **Low intra-cluster similarity** is **not** desirable,\n",
    "* **Low inter-cluster similarity** (clusters are well separated and distinct),\n",
    "* **Well-separated clusters** means clusters don't overlap much.\n",
    "\n",
    "So, **high inter-cluster similarity** means clusters are similar to each other, which is **not** a characteristic of good clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1922e23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efbde544",
   "metadata": {},
   "source": [
    "### Q13. In DBSCAN, what does the parameter 'eps' represent?\n",
    "1. The minimum number of points to form a dense region \n",
    "2. The maximum distance between two points for them to be considered neighbors \n",
    "3. The number of clusters \n",
    "4. The density threshold for noise points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51950343",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. The maximum distance between two points for them to be considered neighbors**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "In DBSCAN, **`eps`** (epsilon) defines the radius around a point within which other points are considered its neighbors. It essentially sets the maximum distance two points can be apart to be included in the same neighborhood or cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a68e3d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d11216e0",
   "metadata": {},
   "source": [
    "### Q14. Which of the following is NOT a type of clustering algorithms? \n",
    "1. Partitioning methods \n",
    "2. Hierarchical methods \n",
    "3. Density-based methods \n",
    "4. Regression methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef6ee6a",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**4. Regression methods**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "* **Partitioning methods** (e.g., K-means),\n",
    "* **Hierarchical methods** (e.g., Agglomerative clustering),\n",
    "* **Density-based methods** (e.g., DBSCAN),\n",
    "\n",
    "are all types of clustering algorithms.\n",
    "\n",
    "**Regression methods** are used for predicting continuous outcomes and are **not** clustering algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88881639",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc54a7a8",
   "metadata": {},
   "source": [
    "### Q15. Which of the following is an example of an extrinsic measure for evaluating clustering? \n",
    "1. Silhouette Coefficient \n",
    "2. Davies-Bouldin Index \n",
    "3. Adjusted Rand Index \n",
    "4. Elbow Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629bdc74",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. Adjusted Rand Index**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "* **Extrinsic (external) measures** evaluate clustering quality by comparing the clustering results to known ground truth labels.\n",
    "* **Adjusted Rand Index (ARI)** measures the similarity between the predicted clusters and true class labels, making it an extrinsic measure.\n",
    "\n",
    "Other options like **Silhouette Coefficient**, **Davies-Bouldin Index**, and **Elbow Method** are **intrinsic** measures that evaluate clustering based only on the data and cluster structure, without using external labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfadeec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "981f0033",
   "metadata": {},
   "source": [
    "### Q16. What is the silhouette Coefficient used for in clustering? \n",
    "1. To determine the optimal number of clusters \n",
    "2. To measure the density of clusters \n",
    "3. To evaluate how well a data point fits into its assigned cluster \n",
    "4. To calculate the distance between cluster centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1fbd33",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. To evaluate how well a data point fits into its assigned cluster**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "The **Silhouette Coefficient** measures how similar a data point is to its own cluster compared to other clusters. It ranges from -1 to 1, where a high value indicates that the data point is well matched to its own cluster and poorly matched to neighboring clusters. It can also be used to assess overall clustering quality and help determine the optimal number of clusters (option 1), but its primary purpose is to evaluate the fit of individual points within clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a497269b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "994859d2",
   "metadata": {},
   "source": [
    "### Q17. In hierarchical clustering, what does a dendrogram represent? \n",
    "1. The distance between data points \n",
    "2. The number of clusters \n",
    "3. The hierarchy of cluster merges or splits \n",
    "4. The density of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9080c9eb",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. The hierarchy of cluster merges or splits**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "A **dendrogram** is a tree-like diagram that illustrates the arrangement of clusters formed by hierarchical clustering. It shows the order and distance at which clusters are merged (agglomerative) or split (divisive), representing the hierarchy of clusters at different levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d2060",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a99b9fc",
   "metadata": {},
   "source": [
    "### Q18. Which clustering algorithm is particularly good at detecting clusters of arbitrary shape and identifying noise? \n",
    "1. K-means \n",
    "2. DBSCAN \n",
    "3. Hierarchical clustering \n",
    "4. K-means++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e814a",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. DBSCAN**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**DBSCAN** (Density-Based Spatial Clustering of Applications with Noise) excels at finding clusters of **arbitrary shape** and can **identify noise points** (outliers) because it groups points based on density rather than predefined cluster shapes like K-means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afdd29a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69070fda",
   "metadata": {},
   "source": [
    "### Q19. What is the main difference between K-means and K-means++? \n",
    "1. K-means++ can handle categorical data \n",
    "2. K-means++ uses a different distance metric \n",
    "3. K-means++ has a smarter initialization of centroids \n",
    "4. K-means++ automatically determines teh number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e388d",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. K-means++ has a smarter initialization of centroids**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "K-means++ improves the standard K-means algorithm by choosing initial centroids more carefully to speed up convergence and improve clustering results. It does **not** change the distance metric, handle categorical data differently, or automatically determine the number of clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d25887",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f029cb20",
   "metadata": {},
   "source": [
    "### Q20. Which of the following is a limitation of K-means clustering? \n",
    "1. It can handle non-linear data \n",
    "2. It's insensitive to initial Centroid placement \n",
    "3. It assumes spherical clusters of similar size \n",
    "4. It can automatically determine the optimal number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ea57b0",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. It assumes spherical clusters of similar size**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "K-means clustering assumes clusters are roughly **spherical** (round) and of **similar size** because it uses the mean and Euclidean distance to assign points. This makes it less effective for clusters with irregular shapes or varying sizes.\n",
    "\n",
    "Other points:\n",
    "\n",
    "* K-means **cannot** handle non-linear cluster shapes well (so option 1 is false).\n",
    "* It **is sensitive** to initial centroid placement (option 2 is false).\n",
    "* It **does not** automatically determine the number of clusters (option 4 is false).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2094fee3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a241665f",
   "metadata": {},
   "source": [
    "### Q21. In K-means clustering, what does the \"K\" represent? \n",
    "1. The number of iterations \n",
    "2. The number of clusters \n",
    "3. The number of features \n",
    "4. The number of data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fdf046",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. The number of clusters**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "In K-means clustering, **\"K\"** specifies the number of clusters that the algorithm will partition the data into. The user sets this value before running the algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42079aa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c44b9ed",
   "metadata": {},
   "source": [
    "### Q22. In the context of clustering evaluation , what does NMI stand for? \n",
    "1. Normalized Mutual Information \n",
    "2. Non-Metric Index \n",
    "3. Numerical Measurement of Improvement \n",
    "4. New Method of Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7225c7",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. Normalized Mutual Information**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**NMI (Normalized Mutual Information)** is an external clustering evaluation metric that measures the similarity between the clustering results and the ground truth labels, normalized to scale between 0 (no mutual information) and 1 (perfect correlation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b982b13",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eb756be",
   "metadata": {},
   "source": [
    "### Q23. What is the main difference between agglomerative and divisive hierarchical clustering? \n",
    "1. Agglomerative is top-down, divisive is bottom-up \n",
    "2. Agglomerative is bottom-up, divisive is top-down \n",
    "3. Agglomerative uses distance, divisive uses similarity \n",
    "4. Agglomerative is for small datasets, divisive for large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a880ec",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Agglomerative is bottom-up, divisive is top-down**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "* **Agglomerative clustering** starts with each data point as its own cluster and merges clusters step-by-step (bottom-up).\n",
    "* **Divisive clustering** starts with all data points in one cluster and splits them recursively (top-down).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af812a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89200093",
   "metadata": {},
   "source": [
    "### Q24. What does the Dunn Index measure in clustering evaluation? \n",
    "1. The ratio of the smallest inter-cluster distance to the largest intra-cluster distance \n",
    "2. The ratio of the largest inter-cluster distance to the smallest intra-cluster distance \n",
    "3. The average distance between clusters \n",
    "4. The density of the most compact cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00217560",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. The ratio of the smallest inter-cluster distance to the largest intra-cluster distance**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "The **Dunn Index** evaluates clustering quality by measuring the ratio between:\n",
    "\n",
    "* The **smallest distance between points in different clusters** (inter-cluster distance),\n",
    "* And the **largest distance between points within the same cluster** (intra-cluster distance).\n",
    "\n",
    "A higher Dunn Index indicates better clustering with well-separated and compact clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64e47f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ae2d6e5",
   "metadata": {},
   "source": [
    "### Q25. Which of the following statements about DBSCAN is TRUE? \n",
    "1. It requires specifying the number of clusters in advance \n",
    "2. It's particulary sensitive to outliers \n",
    "3. It can find clusters of arbitrary shape \n",
    "4. It assumes clusters are spherical and of similar size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2732c803",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. It can find clusters of arbitrary shape**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "DBSCAN is designed to detect clusters of **arbitrary shapes** based on density, making it flexible for various data structures. It **does not require specifying the number of clusters** beforehand (contrary to option 1), is **robust to outliers** (option 2 is false), and does **not assume spherical clusters** (option 4 is false).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a068b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585d33d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71662ede",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc313988",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
