{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a82507",
   "metadata": {},
   "source": [
    "# Quiz : YOLO (You Only Look Once) Assessement\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97e0833",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4859d80",
   "metadata": {},
   "source": [
    "### Q1. What is the primary advantage of YOLO over traditional object detection methods? \n",
    "1. Higher accuracy \n",
    "2. Larger model size \n",
    "3. Single forward pass for detection \n",
    "4. Ability to detect more classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38432b2d",
   "metadata": {},
   "source": [
    "The primary advantage of YOLO over traditional object detection methods is:\n",
    "\n",
    "**3. Single forward pass for detection**\n",
    "\n",
    "YOLO (You Only Look Once) processes the entire image in one pass through the neural network, making it extremely fast compared to traditional methods that use region proposals and multiple stages.\n",
    "YOLO's main advantage is its ability to process the entire image in a single forward pass, simultaneously predicting bounding boxes and class probabilities. This approach contributes to its real-time object detection capabilities, making it significantly faster than traditional methods that require multiple passes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e237a41",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ec15697",
   "metadata": {},
   "source": [
    "### Q2. Which of the following is NOT a typical strategy for improving YOLO's performance on small objects? \n",
    "1. Increasing the input image resolution \n",
    "2. Using feature pyramid networks \n",
    "3. Implementing attention mechanisms \n",
    "4. Reducing the number of anchor boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56443b54",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**4. Reducing the number of anchor boxes**\n",
    "\n",
    "Reducing the number of anchor boxes is generally not a strategy to improve performance on small objects. In fact, having more carefully designed anchor boxes can help detect small objects better. The other options — increasing input resolution, using feature pyramid networks, and implementing attention mechanisms — are typical strategies to enhance small object detection in YOLO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4549e1d4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29f16cbc",
   "metadata": {},
   "source": [
    "### Q3. How does YOLO handle the issue of class imbalance in training data? \n",
    "1. By using weighted loss functions \n",
    "2. By ignoring less frequent classes \n",
    "3. By artificial increasing the number of images for rare classes \n",
    "4. By using separate models for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d038b",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. By using weighted loss functions**\n",
    "\n",
    "YOLO addresses class imbalance during training by applying weighted loss functions, which give more importance to less frequent classes or harder examples, helping the model learn better despite imbalance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e922ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc527921",
   "metadata": {},
   "source": [
    "### Q4. In YOLO v3, what technique is introduced to improve detection of objects at different scales? \n",
    "1. Anchor boxes \n",
    "2. Feature Pyramid Networks (FPN) \n",
    "3. Non-Max Suppression \n",
    "4. Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78799ccb",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. Feature Pyramid Networks (FPN)**\n",
    "\n",
    "YOLO v3 uses a concept similar to Feature Pyramid Networks by making predictions at three different scales, which helps improve detection of objects of varying sizes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560cb9f9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de65fc9b",
   "metadata": {},
   "source": [
    "### Q5. What is the purpose of the confidence score in YOLO's output? \n",
    "1. To determine the class of the object \n",
    "2. To indicate the likelihood of an object's presence and the accuracy of the bounding box \n",
    "3. To calculate the size of the object \n",
    "4. To determine the color of the bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321f93ac",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. To indicate the likelihood of an object's presence and the accuracy of the bounding box**\n",
    "\n",
    "The confidence score in YOLO reflects how confident the model is that an object exists in the predicted bounding box and how accurate that bounding box is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33c0002",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a334a6a6",
   "metadata": {},
   "source": [
    "### Q6. What is the main difference between YOLO v1 and YOLO v2 in terms of bounding box prediction? \n",
    "1. YOLO v2 uses anchor boxes \n",
    "2. YOLO v2 predicts fewer bounding boxes \n",
    "3. YOLO v1 uses a deeper neural network \n",
    "4. YOLO v1 has higher accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193eaaf5",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**1. YOLO v2 uses anchor boxes**\n",
    "\n",
    "YOLO v2 introduced the use of anchor boxes for bounding box prediction, which improved localization accuracy compared to YOLO v1’s direct bounding box prediction approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1558b2df",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b43222d",
   "metadata": {},
   "source": [
    "### Q7. What does the intersection over Union (IoU) metric measure in object detection? \n",
    "1. The speed of detection \n",
    "2. The overlap between predicted and ground truth bounding boxes \n",
    "3. Teh number of objectes in an image \n",
    "4. The size of the detected object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d339a",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. The overlap between predicted and ground truth bounding boxes**\n",
    "\n",
    "IoU measures how much the predicted bounding box overlaps with the actual (ground truth) bounding box, which helps evaluate the accuracy of object detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a94ec8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e82aba17",
   "metadata": {},
   "source": [
    "### Q8. In YOLO, what is the purpose of Non-Max Suppression (NMS)? \n",
    "1. To increase the number of detections \n",
    "2. To improve the model's speed \n",
    "3. To eliminate redundant detections \n",
    "4. To enhance the model's accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de28129",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. To eliminate redundant detections**\n",
    "\n",
    "Non-Max Suppression (NMS) helps remove multiple overlapping bounding boxes for the same object, keeping only the one with the highest confidence score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac58ce46",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ec9b451",
   "metadata": {},
   "source": [
    "### Q9. What is the significance of the grid system in YOLO's architecture? \n",
    "1. It improves the model's accuracy \n",
    "2. It divides the image for parallel processing \n",
    "3. It assigns detection responsibilities to different regions of the image \n",
    "4. It reduces the model's computational reuirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f0b36",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. It assigns detection responsibilities to different regions of the image**\n",
    "\n",
    "YOLO divides the input image into a grid, and each grid cell is responsible for detecting objects whose centers fall within that cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848bdcd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42dc221e",
   "metadata": {},
   "source": [
    "### Q10. Which of the following is NOT a key feature of YOLO v4? \n",
    "1. CSPDarknet53 backbone \n",
    "2. PANet for feature aggregation \n",
    "3. Region Proposal Network (RPN) \n",
    "4. Advanced training startegies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d7783",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. Region Proposal Network (RPN)**\n",
    "\n",
    "YOLO v4 does **not** use a Region Proposal Network, which is typical of two-stage detectors like Faster R-CNN. Instead, YOLO v4 uses a one-stage detection approach with CSPDarknet53 backbone, PANet for feature aggregation, and advanced training strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb24a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07eb0131",
   "metadata": {},
   "source": [
    "### Q11. What is the primary challenge YOLO faces in dense scenes? \n",
    "1. Slow processing speed \n",
    "2. High false positive rate \n",
    "3. Difficulty in detecting small, clustered objects \n",
    "4. Inability to classify objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edddc6f7",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. Difficulty in detecting small, clustered objects**\n",
    "\n",
    "YOLO tends to struggle with accurately detecting small objects that are close together or densely packed, especially in crowded scenes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2095f8fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b471315",
   "metadata": {},
   "source": [
    "### Q12. How does YOLO v3 address the issue of detecting objects at different scales? \n",
    "1. By using a single detection layer \n",
    "2. By implementing three detection layers at different scales \n",
    "3. By increasing the input image size \n",
    "4. By using more anchor boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f95c13",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. By implementing three detection layers at different scales**\n",
    "\n",
    "YOLO v3 uses three separate detection layers that operate at different scales to better detect small, medium, and large objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a760ba62",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd5a8a79",
   "metadata": {},
   "source": [
    "### Q13. What is the purpose of transfer learning in the context of YOLO? \n",
    "1. To improve the model's speed \n",
    "2. To reduce the model's size \n",
    "3. To leverage pre-trained weights for better performance on new tasks \n",
    "4. To enable detection of more object classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07ec11",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. To leverage pre-trained weights for better performance on new tasks**\n",
    "\n",
    "Transfer learning in YOLO uses pre-trained weights from a large dataset to help the model learn faster and perform better when training on a new, possibly smaller, dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e266be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cac8ddba",
   "metadata": {},
   "source": [
    "### Q14. Which of the following is NOT a typical step in preparing data for YOLO training? \n",
    "1. Image annotation with bounding boxes \n",
    "2. Creating a YAML configuration file \n",
    "3. Splitting the datset into train, validation, and test sets \n",
    "4. Converting all images to grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653975bc",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**4. Converting all images to grayscale**\n",
    "\n",
    "YOLO typically uses color images to leverage the full visual information. Converting images to grayscale is not a standard or beneficial step in YOLO training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa0c8d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12ebc39f",
   "metadata": {},
   "source": [
    "### Q15. What does the 'You Only Look Once' in YOLO specifically refer to? \n",
    "1. The model only needs to be trained once \n",
    "2. The image is processed in a single forward pass \n",
    "3. Only one object can be detected per image \n",
    "4. The model only uses one convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9714b0ab",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. The image is processed in a single forward pass**\n",
    "\n",
    "\"You Only Look Once\" means YOLO processes the entire image just once through the network to simultaneously predict bounding boxes and class probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786d137",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd9fd136",
   "metadata": {},
   "source": [
    "### Q16. In YOLO v2 (YOLO9000), how was the model able to detect over 9000 object categories? \n",
    "1. By using a much larger training dataset \n",
    "2. By implementing a hierarchical classification system \n",
    "3. By increasing the model's depth significantly \n",
    "4. By using ensemble learning technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a967f82",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. By implementing a hierarchical classification system**\n",
    "\n",
    "YOLO9000 uses a hierarchical classification based on WordTree, allowing it to predict over 9000 object categories by combining detection and classification datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10159a56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea90dd0a",
   "metadata": {},
   "source": [
    "### Q17. What is the primary purpose of anchor boxes in YOLO? \n",
    "1. To  increase the model's speed \n",
    "2. To improve detection of objects with various aspect ratios \n",
    "3. To reduce the model's memory footprint \n",
    "4. To enable multi-class detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a6c76f",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. To improve detection of objects with various aspect ratios**\n",
    "\n",
    "Anchor boxes help YOLO predict bounding boxes that better fit objects of different shapes and sizes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a6532",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8751339f",
   "metadata": {},
   "source": [
    "### Q18. Which of the following is NOT a typical application of YOLO in autonomous vehicles? \n",
    "1. Pedestrian detection \n",
    "2. Traffic sign recognition \n",
    "3. Engine performance monitoring \n",
    "4. Obstacle detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4905c70b",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. Engine performance monitoring**\n",
    "\n",
    "YOLO is used for visual tasks like pedestrian detection, traffic sign recognition, and obstacle detection, but engine performance monitoring is not a vision-based application and does not involve YOLO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a462f0e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6443a45c",
   "metadata": {},
   "source": [
    "### Q19. What is the significance of the CSPDarknet53 backbone in YOLO v4? \n",
    "1. It reduces the model's size \n",
    "2. It improves feature extraction capabilities \n",
    "3. It enables real-time processing on mobile devices \n",
    "4. It allows for unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5cbe93",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**2. It improves feature extraction capabilities**\n",
    "\n",
    "CSPDarknet53 in YOLO v4 is designed to enhance feature extraction while maintaining efficiency, helping the model learn richer representations for better detection performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924cb65",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e1c4208",
   "metadata": {},
   "source": [
    "### Q20. What is the purpose of the YOLO layer in the network architecture? \n",
    "1. To perform the final classification \n",
    "2. To generate feature maps \n",
    "3. To output bounding box coordinates and class probabilities \n",
    "4. To apply non-max suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92b6e36",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "**3. To output bounding box coordinates and class probabilities**\n",
    "\n",
    "The YOLO layer is responsible for producing the final predictions: bounding box locations, confidence scores, and class probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ccf7c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73964988",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c01bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73936891",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
