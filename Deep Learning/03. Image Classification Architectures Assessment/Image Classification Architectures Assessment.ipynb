{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "838fba3a",
   "metadata": {},
   "source": [
    "# Quiz : Image Classification Architectures Assessment\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a1c2d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49cd9256",
   "metadata": {},
   "source": [
    "### Q1. What was the primary application of LeNet when it was first introduced? \n",
    "1. ImageNet classification \n",
    "2. Handwritten digit recognition \n",
    "3. Object detection \n",
    "4. Video classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb53ce7",
   "metadata": {},
   "source": [
    "The correct answer is **2. Handwritten digit recognition**.\n",
    "\n",
    "LeNet, introduced by Yann LeCun in the late 1980s and popularized in the 1990s, was primarily used for recognizing handwritten digits, such as those in the **MNIST** dataset, for applications like automated check processing in banks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ec397",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13b9afb1",
   "metadata": {},
   "source": [
    "### Q2. ResNet won the ILSVRC competition in which year? \n",
    "1. 2014 \n",
    "2. 2015 \n",
    "3. 2017 \n",
    "4. 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c201f6",
   "metadata": {},
   "source": [
    "The correct answer is **2. 2015**.\n",
    "\n",
    "ResNet (Residual Networks) by Microsoft Research won the **ImageNet Large Scale Visual Recognition Challenge (ILSVRC)** in 2015 with a top-5 error rate of just 3.57%, introducing the concept of **skip connections** to train very deep networks effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f7252a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f21ec0e",
   "metadata": {},
   "source": [
    "### Q3. ResNet's skip connections help by: \n",
    "1. Decreasing the depth of the network \n",
    "2. Improving convergence by allowing gradients to flow directly \n",
    "3. Replacing fully connected layers \n",
    "4. Reducing the need for pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb4ad91",
   "metadata": {},
   "source": [
    "The correct answer is **2. Improving convergence by allowing gradients to flow directly**.\n",
    "\n",
    "Skip connections in ResNet let the gradient bypass some layers during backpropagation, which helps **mitigate the vanishing gradient problem** and makes it possible to train much deeper networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65535f0e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "751405a7",
   "metadata": {},
   "source": [
    "### Q4. ResNet introduced which key architectural innovation? \n",
    "1. Recurrent modules \n",
    "2. Skip (residual) connections \n",
    "3. Dense connections \n",
    "4. Fully connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3c621",
   "metadata": {},
   "source": [
    "The correct answer is **2. Skip (residual) connections**.\n",
    "\n",
    "This innovation allowed ResNet to train networks with **hundreds or even thousands of layers** by letting the model learn **residual mappings** instead of direct transformations, making deep architectures far more practical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42f52d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c122f4d",
   "metadata": {},
   "source": [
    "### Q5. Which type of pooling is used in VGGNet? \n",
    "1. Max pooling \n",
    "2. Average pooling \n",
    "3. Global average pooling \n",
    "4. Fractional pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea19a2a",
   "metadata": {},
   "source": [
    "The correct answer is **1. Max pooling**.\n",
    "\n",
    "VGGNet uses **max pooling layers** (typically with a (2 \\times 2) window and stride 2) to progressively reduce the spatial dimensions while retaining the most important features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a4a91",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9dd5c6b",
   "metadata": {},
   "source": [
    "### Q6. The original VGGNet architecture has how many layers? \n",
    "1. 11 to 19 layers \n",
    "2. 22 layers \n",
    "3. 34 layers \n",
    "4. 50 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c253f9",
   "metadata": {},
   "source": [
    "The correct answer is **1. 11 to 19 layers**.\n",
    "\n",
    "The original VGGNet paper (by Simonyan and Zisserman, 2014) described configurations ranging from **VGG-11** to **VGG-19**, where the number refers to the total count of **convolutional + fully connected layers**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2644e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26bc1db1",
   "metadata": {},
   "source": [
    "### Q7. Transfer learning is mostly used in deep learning to: \n",
    "1. Reduce the training time of models \n",
    "2. Increase the number of parameters \n",
    "3. Perform unsupervised learning \n",
    "4. Improve hardware performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019693bc",
   "metadata": {},
   "source": [
    "The correct answer is **1. Reduce the training time of models**.\n",
    "\n",
    "In deep learning, **transfer learning** leverages pre-trained models (often trained on large datasets like ImageNet) so you can **reuse learned features** for a new but related task, which greatly **reduces training time** and often improves performance with limited data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0062d4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d5ec879",
   "metadata": {},
   "source": [
    "### Q8. Pre-trained models for transfer learning are often trained on which dataset? \n",
    "1. MNIST \n",
    "2. ImageNet \n",
    "3. CIFAR-10 \n",
    "4. Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab8f2df",
   "metadata": {},
   "source": [
    "The correct answer is **2. ImageNet**.\n",
    "\n",
    "ImageNet contains over **14 million labeled images across 1,000 classes**, making it a popular choice for training **pre-trained models** used in transfer learning for various computer vision tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8502b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "092a0892",
   "metadata": {},
   "source": [
    "### Q9. Which dataset did LeNet primarily work on? \n",
    "1. CIFAR-10 \n",
    "2. MNIST \n",
    "3. ImageNet \n",
    "4. Pascal VOC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6e8e0",
   "metadata": {},
   "source": [
    "The correct answer is **2. MNIST**.\n",
    "\n",
    "LeNet was primarily used for **handwritten digit recognition** on the MNIST dataset, which contains **70,000 grayscale images** of digits (0)–(9).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d0ec1f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acc69b32",
   "metadata": {},
   "source": [
    "### Q10. LeNet was developed by which of the following researchers? \n",
    "1. Yann LeCun \n",
    "2. Geoffrey Hinton \n",
    "3. Alex Krizhevsky \n",
    "4. Kaiming He"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293aae31",
   "metadata": {},
   "source": [
    "The correct answer is **1. Yann LeCun**.\n",
    "\n",
    "Yann LeCun developed **LeNet** in the late 1980s–1990s, pioneering convolutional neural networks for tasks like **handwritten digit recognition**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106152ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e948811",
   "metadata": {},
   "source": [
    "### Q11. What is the main component of LeNet architecture? \n",
    "1. Fully coonected layers \n",
    "2. Convolutional and pooling layers \n",
    "3. Recurrent layers \n",
    "4. Skip connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d295a8b",
   "metadata": {},
   "source": [
    "The correct answer is **2. Convolutional and pooling layers**.\n",
    "\n",
    "LeNet’s architecture mainly consists of **convolutional layers** (for feature extraction) and **average pooling layers** (called subsampling in the original paper), followed by a few fully connected layers for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7f8b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bc7c10a",
   "metadata": {},
   "source": [
    "### Q12. How many convolutional layers are in the LeNet-5 architecture? \n",
    "1. 2 \n",
    "2. 3 \n",
    "3. 4 \n",
    "4. 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00cc34",
   "metadata": {},
   "source": [
    "The correct answer is **1. 2**.\n",
    "\n",
    "LeNet-5 contains **two convolutional layers** (C1 and C3), each followed by subsampling (pooling) layers, then fully connected layers for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901952ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ed3a331",
   "metadata": {},
   "source": [
    "### Q13. AlexNet achieved a breakthrough by wining which competition? \n",
    "1. MNIST Challenge \n",
    "2. CIFAR-10 Challenge \n",
    "3. ImageNet Large Scale Visual Recognition Challenge (ILSVRC) \n",
    "4. COCO Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21bac55",
   "metadata": {},
   "source": [
    "The correct answer is **3. ImageNet Large Scale Visual Recognition Challenge (ILSVRC)**.\n",
    "\n",
    "AlexNet won the **ILSVRC 2012** competition by a large margin, demonstrating the power of deep convolutional networks trained on GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd62b1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2211823",
   "metadata": {},
   "source": [
    "### Q14. One of the key features of AlexNet was the use of: \n",
    "1. Sigmoid activation \n",
    "2. ReLU activation \n",
    "3. Tanh activation \n",
    "4. Softmax activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a176d",
   "metadata": {},
   "source": [
    "The correct answer is **2. ReLU activation**.\n",
    "\n",
    "AlexNet popularized the use of **ReLU (Rectified Linear Unit)** activation, which helped speed up training and mitigate the **vanishing gradient problem** compared to sigmoid or tanh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a927b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56e7324c",
   "metadata": {},
   "source": [
    "### Q15. How many convolutional layers are in AlexNet? \n",
    "1. 5 \n",
    "2. 3 \n",
    "3. 7 \n",
    "4. 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e186de",
   "metadata": {},
   "source": [
    "The correct answer is **1. 5**.\n",
    "\n",
    "AlexNet’s architecture has **5 convolutional layers** followed by **3 fully connected layers**, making a total of 8 learnable layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d816855",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f03707a5",
   "metadata": {},
   "source": [
    "### 16. What technique dis AlexNet use to address overfitting? \n",
    "1. Batch Normalization \n",
    "2. Data Augmentation \n",
    "3. Skip connections \n",
    "4. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b1a994",
   "metadata": {},
   "source": [
    "The correct answer is **4. Dropout**.\n",
    "\n",
    "AlexNet used **dropout** in the fully connected layers to reduce overfitting by randomly disabling a fraction of neurons during training. It also used **data augmentation**, but dropout was the more notable innovation for regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1314e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "256e56c6",
   "metadata": {},
   "source": [
    "### Q17. AlexNet primarily uses which of the following pooling methods? \n",
    "1. Max Pooling \n",
    "2. Average Pooling \n",
    "3. Global average pooling \n",
    "4. Strideed convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216bbc69",
   "metadata": {},
   "source": [
    "The correct answer is **1. Max Pooling**.\n",
    "\n",
    "AlexNet primarily used **max pooling layers** to reduce spatial dimensions while retaining the most important features in the feature maps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20bf1b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0a67c83",
   "metadata": {},
   "source": [
    "### Q18. GoogLeNet introduced which type of module that was central to its success? \n",
    "1. Recurrent module \n",
    "2. Skip connections \n",
    "3. Inception module \n",
    "4. Dense module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc0092a",
   "metadata": {},
   "source": [
    "The correct answer is **3. Inception module**.\n",
    "\n",
    "GoogLeNet (Inception v1) introduced the **Inception module**, which processes input with multiple filter sizes in parallel and concatenates the results, allowing the network to capture features at different scales efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd86a81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "335a92c4",
   "metadata": {},
   "source": [
    "### Q19. How many layers does the GoogLeNet architecture approximately have? \n",
    "1. 12 \n",
    "2. 22 \n",
    "3. 34 \n",
    "4. 50'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc3dd3",
   "metadata": {},
   "source": [
    "The correct answer is **2. 22**.\n",
    "\n",
    "GoogLeNet (Inception v1) has **22 layers** deep (including convolutional and fully connected layers) and uses the **Inception modules** to achieve high performance with fewer parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05768fb4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5280815c",
   "metadata": {},
   "source": [
    "### Q20. GoogLeNet introduced the concept of: \n",
    "1. Auxiliary classifiers \n",
    "2. Batch normalization \n",
    "3. Strided convolution \n",
    "4. Maxout activation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b05723",
   "metadata": {},
   "source": [
    "The correct answer is **1. Auxiliary classifiers**.\n",
    "\n",
    "GoogLeNet included **auxiliary classifiers**—small side networks attached to intermediate layers—to help with gradient flow during training and act as regularizers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e914ff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5f0213d",
   "metadata": {},
   "source": [
    "### Q21. Which of the following is a key feature of the Inception module in GoogLeNet? \n",
    "1. Combining multiple convolutional fiter sizes in parallel \n",
    "2. Recurrent layers for memory \n",
    "3. Using fully connected layers after every convolution \n",
    "4. Sequential layers of the same filter size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356ef8d",
   "metadata": {},
   "source": [
    "The correct answer is **1. Combining multiple convolutional filter sizes in parallel**.\n",
    "\n",
    "The Inception module applies **different convolution filter sizes (e.g., 1x1, 3x3, 5x5)** in parallel on the same input and concatenates their outputs, capturing features at multiple scales efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10609a92",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa7cc320",
   "metadata": {},
   "source": [
    "### Q22. GoogLeNet won the ILSVRC competition in which year? \n",
    "1. 2012 \n",
    "2. 2013 \n",
    "3. 2014 \n",
    "4. 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ab679",
   "metadata": {},
   "source": [
    "The correct answer is **3. 2014**.\n",
    "\n",
    "GoogLeNet won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in **2014**, achieving a top-5 error rate of 6.67%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ea498",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d93dc4a",
   "metadata": {},
   "source": [
    "### Q23. Transfer learning is most useful when: \n",
    "1. You have a large dataset and a simple model \n",
    "2. You have a small dataset and a complex model \n",
    "3. You have a small dataset and no pre-trained models \n",
    "4. You have a large dataset and no pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8202d738",
   "metadata": {},
   "source": [
    "The correct answer is **2. You have a small dataset and a complex model**.\n",
    "\n",
    "Transfer learning helps especially when your dataset is small, but the model is complex and would otherwise require lots of data and time to train from scratch. Using a pre-trained model lets you leverage learned features to improve performance and reduce training effort.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1b1f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e42992ff",
   "metadata": {},
   "source": [
    "### Q24. In transfer learning, typically: \n",
    "1. You start training a model from scratch \n",
    "2. You fine-tune a pre-trained model \n",
    "3. You always use the same dataset \n",
    "4. You discard the pre-trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdafab3",
   "metadata": {},
   "source": [
    "The correct answer is **2. You fine-tune a pre-trained model**.\n",
    "\n",
    "In transfer learning, you usually start with a model pre-trained on a large dataset (like ImageNet) and then **fine-tune** it on your specific task or dataset to adapt the learned features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a048e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1181386a",
   "metadata": {},
   "source": [
    "### Q25. Which is a common approach in transfer learning? \n",
    "1. Use a small dataset to train a model with no pre-trained \n",
    "2. Replace the final layers of a pre-trained model for a new task \n",
    "3. Remove convolutional layers and replace with pooling layers \n",
    "4. Only use the pre-trained model without any changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71e9907",
   "metadata": {},
   "source": [
    "The correct answer is **2. Replace the final layers of a pre-trained model for a new task**.\n",
    "\n",
    "A common transfer learning approach is to keep the convolutional base of a pre-trained model and **replace the final fully connected (classification) layers** to match the new task’s number of classes, then train those layers (and sometimes fine-tune earlier layers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af4d68",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63cb3555",
   "metadata": {},
   "source": [
    "### Q26. VGGNet is characteristic by using : \n",
    "1. 3x3 convolutional filters \n",
    "2. 7x7 convolutional filters \n",
    "3. 1x1 convolutional filters \n",
    "4. Inception modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b42234",
   "metadata": {},
   "source": [
    "The correct answer is **1. 3x3 convolutional filters**.\n",
    "\n",
    "VGGNet is known for using **very small (3 \\times 3) convolutional filters** stacked deeply to build the network, which helps capture fine details while keeping the number of parameters manageable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84774eee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a40ce025",
   "metadata": {},
   "source": [
    "### Q27. What is the primary disadvantage of VGGNet? \n",
    "1. Complex Inception modules \n",
    "2. High Computational cost due to deep layers \n",
    "3. Poor accuracy on ImageNet \n",
    "4. Lack of fully connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd7a1aa",
   "metadata": {},
   "source": [
    "The correct answer is **2. High computational cost due to deep layers**.\n",
    "\n",
    "While VGGNet achieved strong accuracy, its main drawback is that it’s **computationally expensive and memory-intensive** because of its deep architecture and large number of parameters, especially in the fully connected layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84bf4b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c64e5be",
   "metadata": {},
   "source": [
    "### Q28. What is the main advantage of VGGNet? \n",
    "1. Simplicity in design and strong performance \n",
    "2. Very few parameters \n",
    "3. Use of large convolution filters \n",
    "4. Extremely fast training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf7cfe",
   "metadata": {},
   "source": [
    "The correct answer is **1. Simplicity in design and strong performance**.\n",
    "\n",
    "VGGNet’s straightforward use of stacked small (3 \\times 3) convolutional layers makes its architecture simple to understand and implement, while still achieving strong accuracy on challenging datasets like ImageNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d07ff5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4807c30",
   "metadata": {},
   "source": [
    "### Q29. The problem that ResNet is designed to solve is: \n",
    "1. Vanishing gradient problem in deep networks \n",
    "2. Overfitting \n",
    "3. Lack of convolutional layers \n",
    "4. Poor data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c17671",
   "metadata": {},
   "source": [
    "The correct answer is **1. Vanishing gradient problem in deep networks**.\n",
    "\n",
    "ResNet’s **skip (residual) connections** help mitigate the vanishing gradient issue, enabling very deep networks to train effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6f449",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6186601d",
   "metadata": {},
   "source": [
    "### Q30. How many layers does ResNet-50 have? \n",
    "1. 34 \n",
    "2. 50 \n",
    "3. 101 \n",
    "4. 152"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a4b285",
   "metadata": {},
   "source": [
    "The correct answer is **2. 50**.\n",
    "\n",
    "ResNet-50 is a version of ResNet architecture with **50 layers**, including convolutional, batch normalization, and fully connected layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d767a98",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79098f58",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4414d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f9bd35",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
